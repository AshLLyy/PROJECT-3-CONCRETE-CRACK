# -*- coding: utf-8 -*-
"""project_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Aa_DGf3c5JPlf3Ozds7W_e0yCabvCAsd
"""

!pip install Augmentor

import keras
import Augmentor
import numpy as np
import os, datetime
import tensorflow as tf
import matplotlib.pyplot as plt

from keras import layers,losses, metrics, activations, optimizers, initializers, regularizers, callbacks, applications, preprocessing, models

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard

"""DOWNLOAD DATASET"""

!wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/5y9wdsg2zt-2.zip

!unzip "5y9wdsg2zt-2.zip"

!unrar x "Concrete Crack Images for Classification.rar" "/content/new_dataset/" #auto create folder in content

def augment(path):
    """
    Augments images in the specified path using the Augmentor library.

    Parameters:
        path (str): The directory containing the images to be augmented.
    """
    # Set up the pipeline
    source_dir = path
    output_dir = os.path.join(path, "augmented")

    # Create Augmentor pipeline
    p = Augmentor.Pipeline(source_directory=source_dir, output_directory=output_dir)

    # Add augmentation operations
    p.rotate(probability=0.7, max_left_rotation=13, max_right_rotation=13)
    p.flip_left_right(probability=0.5)  # Example of another operation (optional)
    p.zoom_random(probability=0.5, percentage_area=0.8)  # Optional zoom augmentation

    # Generate augmented images
    num_samples = 40000  # Number of augmented images to generate
    p.sample(num_samples)
    print(f"Augmented images saved to: {output_dir}")

# Define the PATH
PATH = os.path.join('/content/new_dataset')

# Run the augment function
augment(PATH)

NEW_PATH = os.path.join('/content/new_dataset/augmented')

BATCH_SIZE = 32
IMG_SIZE = (160,160)

train_dataset = keras.preprocessing.image_dataset_from_directory(NEW_PATH,   #data file
                                                         shuffle=True,
                                                         batch_size=BATCH_SIZE,
                                                         image_size=IMG_SIZE,
                                                         seed=42,
                                                         validation_split=0.2, #only for validation
                                                         subset="training")

val_dataset = keras.preprocessing.image_dataset_from_directory(NEW_PATH,
                                                         shuffle=True,
                                                         batch_size=BATCH_SIZE,
                                                         image_size=IMG_SIZE,
                                                         seed=42,
                                                         validation_split=0.2,
                                                         subset="validation")

class_name = train_dataset.class_names
batch_1 = train_dataset.take(1)
for images, label in batch_1:
    for i in range(9):
        plt.subplot(3,3,i+1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(images[i].numpy().astype('uint8'))
        plt.title(class_name[label[i]])
plt.show()

nBatches = val_dataset.cardinality().numpy()

validation_dataset = val_dataset.take(nBatches//2)
test_dataset = val_dataset.skip(nBatches//2)

validation_dataset

validation_dataset = validation_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
test_dataset = validation_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)

preprocess_input = applications.resnet.preprocess_input

IMG_SHAPE = IMG_SIZE + (3,)
base_model = applications.ResNet101V2(input_shape=IMG_SHAPE, include_top=False,)

base_model.trainable = False
base_model.summary()

global_avg = layers.GlobalAveragePooling2D()
output_layer = layers.Dense(len(class_name), activation='softmax')

"""FIRST TRAINING ARCHITECTURE"""

inputs = keras.Input(shape=IMG_SHAPE)

x = preprocess_input(inputs)

x = base_model(x)

x = global_avg(x)
x = layers.Dense(32, activation='relu')(x)
x = layers.Dropout(0.3)(x)

outputs = output_layer(x)

model = keras.Model(inputs, outputs)
model.summary()

optimizer = optimizers.Adam(learning_rate=0.0001)
model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

validation_dataset

print(model.evaluate(validation_dataset))

early_stopping = callbacks.EarlyStopping(patience=3,verbose=1)

EPOCHS = 5

history_first = model.fit(train_dataset, validation_data=validation_dataset, epochs=EPOCHS, callbacks=[early_stopping])      #, tensorboard_callback])

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

print(model.evaluate(test_dataset))

plt.plot(history_first.history['loss'])
plt.plot(history_first.history['val_loss'])
plt.legend(["loss", "val_loss"])
plt.show()

for image_batch, label_batch in test_dataset.take(1):
    predictions = np.argmax(model.predict(image_batch), axis=1)
    prediction_class = [class_name[x] for x in predictions]


print(prediction_class)

plt.figure(figsize=(15,15))
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(image_batch[i].numpy().astype('uint8'))
    plt.title(f"prediction: {prediction_class[i]}, label: {class_name[label_batch[i]]}")
plt.show()

model.save('cnn_model.h5')